---
# Karpenter NodePool Configuration for AltaNova Production
# 
# IMPORTANT: The EKS cluster has a small managed node group (2x t3.small) that runs:
#   - Karpenter controller itself
#   - CoreDNS
#   - AWS Load Balancer Controller
#   - Other system components
#
# These NodePools define how Karpenter provisions nodes for APPLICATION WORKLOADS.
# All your application pods will run on nodes created by Karpenter, NOT on the managed node group.

apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: general-purpose
  namespace: karpenter
spec:
  # Template for nodes that Karpenter will create
  template:
    metadata:
      labels:
        workload: general
        environment: prod
        managed-by: karpenter
    
    spec:
      # Node requirements - Karpenter will select best instances matching these
      requirements:
        # Instance types - t3.medium for cost optimization
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - t3.medium
            - t3a.medium  # AMD alternative (often cheaper)
        
        # Capacity type - SPOT for cost savings with on-demand fallback
        - key: karpenter.sh/capacity-type
          operator: In
          values:
            - spot       # Primary choice for cost savings
            - on-demand  # Fallback for critical workloads
        
        # Architecture
        - key: kubernetes.io/arch
          operator: In
          values:
            - amd64
        
        # Availability zones - 3 AZs for production HA
        - key: topology.kubernetes.io/zone
          operator: In
          values:
            - eu-west-1a
            - eu-west-1b
            - eu-west-1c
      
      # Node class reference
      nodeClassRef:
        name: default
      
      # Taints (optional - for dedicated workloads)
      taints: []
  
  # Limits for this NodePool - Higher for production
  limits:
    cpu: "200"      # Max 200 vCPUs across all nodes in this pool
    memory: 400Gi   # Max 400GB memory across all nodes in this pool
  
  # Disruption budget - how Karpenter can replace nodes
  disruption:
    # Consolidation - automatically replace nodes for better bin packing
    consolidationPolicy: WhenUnderutilized
    
    # How long to wait before considering node for consolidation
    # Longer in prod to avoid unnecessary churn
    consolidateAfter: 60s
    
    # Maximum percentage of nodes that can be disrupted at once
    budgets:
      - nodes: "5%"  # More conservative in production
        reasons:
          - Underutilized
          - Empty

---
# Production NodePool for critical workloads (on-demand only)
apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: critical-workloads
  namespace: karpenter
spec:
  template:
    metadata:
      labels:
        workload: critical
        environment: prod
        managed-by: karpenter
    
    spec:
      requirements:
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - t3.medium
            - t3a.medium
        
        # On-demand ONLY for critical workloads
        - key: karpenter.sh/capacity-type
          operator: In
          values:
            - on-demand
        
        - key: kubernetes.io/arch
          operator: In
          values:
            - amd64
        
        - key: topology.kubernetes.io/zone
          operator: In
          values:
            - eu-west-1a
            - eu-west-1b
            - eu-west-1c
      
      nodeClassRef:
        name: default
      
      # Taint for critical workloads only
      taints:
        - key: workload
          value: critical
          effect: NoSchedule
  
  limits:
    cpu: "50"
    memory: 100Gi
  
  disruption:
    consolidationPolicy: WhenEmpty  # Only consolidate when completely empty
    consolidateAfter: 300s          # Wait 5 minutes before consolidating

---
# Karpenter EC2NodeClass - defines AWS-specific configuration
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: default
  namespace: karpenter
spec:
  # AMI selection - use latest EKS-optimized AMI
  amiFamily: AL2
  
  # Subnet selection - use private subnets
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: altanova-prod
  
  # Security group selection
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: altanova-prod
  
  # IAM role for nodes
  role: KarpenterNodeRole-altanova-prod
  
  # User data for node initialization
  userData: |
    #!/bin/bash
    echo "Production node provisioned by Karpenter"
    # Add any custom initialization here
  
  # Block device mappings - larger for production
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 50Gi      # Larger disk for production
        volumeType: gp3
        iops: 3000            # Better performance
        throughput: 125
        encrypted: true
        deleteOnTermination: true
  
  # Metadata options - IMDSv2 required for security
  metadataOptions:
    httpEndpoint: enabled
    httpProtocolIPv6: disabled
    httpPutResponseHopLimit: 2
    httpTokens: required  # IMDSv2 required for security
  
  # Tags for instances
  tags:
    Name: altanova-prod-karpenter-node
    Environment: prod
    ManagedBy: Karpenter
    Project: AltaNova
    karpenter.sh/discovery: altanova-prod
    Backup: "true"  # Tag for backup automation
